{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e4cacbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shivam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aab714c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv ('C:/Users/Shivam/Twitter/output.csv')\n",
    "#selecting only the tweets which have been categorised as offensive by our model\n",
    "df = df.loc[df[\"Prediction\"] ==1 ]\n",
    "#print(df)\n",
    "print(len(df. index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80959cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RTs@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b9a1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df.tweet.apply(clean_tweet)\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17cb749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:4: DeprecationWarning: invalid escape sequence \\w\n",
      "C:\\Users\\Shivam\\AppData\\Local\\Temp/ipykernel_14096/3813916862.py:4: DeprecationWarning: invalid escape sequence \\w\n",
      "  vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
      "C:\\Users\\Shivam\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "# apply transformation\n",
    "tf = vectorizer.fit_transform(df['clean_tweet']).toarray()\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4920b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(tf_feature_names)\n",
    "# print(tf.shape)\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "number_of_topics = 10\n",
    "\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)\n",
    "model.fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c25f72bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "      <th>Topic 4 words</th>\n",
       "      <th>Topic 4 weights</th>\n",
       "      <th>Topic 5 words</th>\n",
       "      <th>Topic 5 weights</th>\n",
       "      <th>Topic 6 words</th>\n",
       "      <th>Topic 6 weights</th>\n",
       "      <th>Topic 7 words</th>\n",
       "      <th>Topic 7 weights</th>\n",
       "      <th>Topic 8 words</th>\n",
       "      <th>Topic 8 weights</th>\n",
       "      <th>Topic 9 words</th>\n",
       "      <th>Topic 9 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>’t</td>\n",
       "      <td>60.5</td>\n",
       "      <td>politician</td>\n",
       "      <td>70.5</td>\n",
       "      <td>amp</td>\n",
       "      <td>100.0</td>\n",
       "      <td>politician</td>\n",
       "      <td>198.7</td>\n",
       "      <td>politician</td>\n",
       "      <td>62.4</td>\n",
       "      <td>polit</td>\n",
       "      <td>92.9</td>\n",
       "      <td>politician</td>\n",
       "      <td>76.4</td>\n",
       "      <td>’</td>\n",
       "      <td>121.0</td>\n",
       "      <td>polit</td>\n",
       "      <td>319.4</td>\n",
       "      <td>politician</td>\n",
       "      <td>51.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>52.1</td>\n",
       "      <td>right</td>\n",
       "      <td>46.1</td>\n",
       "      <td>polit</td>\n",
       "      <td>67.8</td>\n",
       "      <td>need</td>\n",
       "      <td>43.4</td>\n",
       "      <td>stop</td>\n",
       "      <td>54.1</td>\n",
       "      <td>make</td>\n",
       "      <td>43.6</td>\n",
       "      <td>would</td>\n",
       "      <td>71.2</td>\n",
       "      <td>it</td>\n",
       "      <td>71.0</td>\n",
       "      <td>peopl</td>\n",
       "      <td>54.8</td>\n",
       "      <td>call</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>live</td>\n",
       "      <td>41.9</td>\n",
       "      <td>good</td>\n",
       "      <td>32.8</td>\n",
       "      <td>come</td>\n",
       "      <td>39.1</td>\n",
       "      <td>know</td>\n",
       "      <td>34.5</td>\n",
       "      <td>chang</td>\n",
       "      <td>33.1</td>\n",
       "      <td>care</td>\n",
       "      <td>34.1</td>\n",
       "      <td>peopl</td>\n",
       "      <td>55.4</td>\n",
       "      <td>one</td>\n",
       "      <td>66.1</td>\n",
       "      <td>get</td>\n",
       "      <td>38.3</td>\n",
       "      <td>law</td>\n",
       "      <td>28.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>don</td>\n",
       "      <td>41.2</td>\n",
       "      <td>much</td>\n",
       "      <td>31.1</td>\n",
       "      <td>state</td>\n",
       "      <td>32.1</td>\n",
       "      <td>support</td>\n",
       "      <td>28.1</td>\n",
       "      <td>power</td>\n",
       "      <td>29.1</td>\n",
       "      <td>american</td>\n",
       "      <td>30.6</td>\n",
       "      <td>vote</td>\n",
       "      <td>48.2</td>\n",
       "      <td>politician</td>\n",
       "      <td>40.1</td>\n",
       "      <td>go</td>\n",
       "      <td>30.4</td>\n",
       "      <td>’</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>countri</td>\n",
       "      <td>40.1</td>\n",
       "      <td>money</td>\n",
       "      <td>28.0</td>\n",
       "      <td>even</td>\n",
       "      <td>26.6</td>\n",
       "      <td>go</td>\n",
       "      <td>24.2</td>\n",
       "      <td>also</td>\n",
       "      <td>27.9</td>\n",
       "      <td>sport</td>\n",
       "      <td>30.3</td>\n",
       "      <td>trump</td>\n",
       "      <td>41.0</td>\n",
       "      <td>polit</td>\n",
       "      <td>37.7</td>\n",
       "      <td>person</td>\n",
       "      <td>26.4</td>\n",
       "      <td>day</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>think</td>\n",
       "      <td>38.2</td>\n",
       "      <td>peopl</td>\n",
       "      <td>27.5</td>\n",
       "      <td>today</td>\n",
       "      <td>26.1</td>\n",
       "      <td>republican</td>\n",
       "      <td>21.1</td>\n",
       "      <td>like</td>\n",
       "      <td>26.5</td>\n",
       "      <td>play</td>\n",
       "      <td>29.1</td>\n",
       "      <td>take</td>\n",
       "      <td>28.4</td>\n",
       "      <td>thing</td>\n",
       "      <td>24.3</td>\n",
       "      <td>us</td>\n",
       "      <td>25.1</td>\n",
       "      <td>way</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>’m</td>\n",
       "      <td>28.1</td>\n",
       "      <td>media</td>\n",
       "      <td>25.6</td>\n",
       "      <td>parti</td>\n",
       "      <td>25.5</td>\n",
       "      <td>start</td>\n",
       "      <td>19.5</td>\n",
       "      <td>’t</td>\n",
       "      <td>19.1</td>\n",
       "      <td>talk</td>\n",
       "      <td>24.3</td>\n",
       "      <td>presid</td>\n",
       "      <td>27.7</td>\n",
       "      <td>time</td>\n",
       "      <td>20.4</td>\n",
       "      <td>see</td>\n",
       "      <td>23.2</td>\n",
       "      <td>work</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>politician</td>\n",
       "      <td>26.7</td>\n",
       "      <td>like</td>\n",
       "      <td>21.4</td>\n",
       "      <td>know</td>\n",
       "      <td>24.9</td>\n",
       "      <td>think</td>\n",
       "      <td>19.5</td>\n",
       "      <td>need</td>\n",
       "      <td>13.5</td>\n",
       "      <td>peopl</td>\n",
       "      <td>16.6</td>\n",
       "      <td>work</td>\n",
       "      <td>20.9</td>\n",
       "      <td>mani</td>\n",
       "      <td>18.0</td>\n",
       "      <td>trump</td>\n",
       "      <td>20.1</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>polit</td>\n",
       "      <td>24.3</td>\n",
       "      <td>us</td>\n",
       "      <td>20.9</td>\n",
       "      <td>like</td>\n",
       "      <td>12.0</td>\n",
       "      <td>time</td>\n",
       "      <td>17.6</td>\n",
       "      <td>get</td>\n",
       "      <td>12.4</td>\n",
       "      <td>still</td>\n",
       "      <td>13.7</td>\n",
       "      <td>us</td>\n",
       "      <td>20.8</td>\n",
       "      <td>say</td>\n",
       "      <td>17.3</td>\n",
       "      <td>want</td>\n",
       "      <td>18.2</td>\n",
       "      <td>let</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>life</td>\n",
       "      <td>18.1</td>\n",
       "      <td>govern</td>\n",
       "      <td>18.9</td>\n",
       "      <td>make</td>\n",
       "      <td>7.5</td>\n",
       "      <td>year</td>\n",
       "      <td>16.5</td>\n",
       "      <td>want</td>\n",
       "      <td>10.0</td>\n",
       "      <td>time</td>\n",
       "      <td>12.2</td>\n",
       "      <td>get</td>\n",
       "      <td>19.5</td>\n",
       "      <td>’t</td>\n",
       "      <td>14.2</td>\n",
       "      <td>keep</td>\n",
       "      <td>15.9</td>\n",
       "      <td>job</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
       "0            ’t            60.5    politician            70.5           amp   \n",
       "1             i            52.1         right            46.1         polit   \n",
       "2          live            41.9          good            32.8          come   \n",
       "3           don            41.2          much            31.1         state   \n",
       "4       countri            40.1         money            28.0          even   \n",
       "5         think            38.2         peopl            27.5         today   \n",
       "6            ’m            28.1         media            25.6         parti   \n",
       "7    politician            26.7          like            21.4          know   \n",
       "8         polit            24.3            us            20.9          like   \n",
       "9          life            18.1        govern            18.9          make   \n",
       "\n",
       "  Topic 2 weights Topic 3 words Topic 3 weights Topic 4 words Topic 4 weights  \\\n",
       "0           100.0    politician           198.7    politician            62.4   \n",
       "1            67.8          need            43.4          stop            54.1   \n",
       "2            39.1          know            34.5         chang            33.1   \n",
       "3            32.1       support            28.1         power            29.1   \n",
       "4            26.6            go            24.2          also            27.9   \n",
       "5            26.1    republican            21.1          like            26.5   \n",
       "6            25.5         start            19.5            ’t            19.1   \n",
       "7            24.9         think            19.5          need            13.5   \n",
       "8            12.0          time            17.6           get            12.4   \n",
       "9             7.5          year            16.5          want            10.0   \n",
       "\n",
       "  Topic 5 words Topic 5 weights Topic 6 words Topic 6 weights Topic 7 words  \\\n",
       "0         polit            92.9    politician            76.4             ’   \n",
       "1          make            43.6         would            71.2            it   \n",
       "2          care            34.1         peopl            55.4           one   \n",
       "3      american            30.6          vote            48.2    politician   \n",
       "4         sport            30.3         trump            41.0         polit   \n",
       "5          play            29.1          take            28.4         thing   \n",
       "6          talk            24.3        presid            27.7          time   \n",
       "7         peopl            16.6          work            20.9          mani   \n",
       "8         still            13.7            us            20.8           say   \n",
       "9          time            12.2           get            19.5            ’t   \n",
       "\n",
       "  Topic 7 weights Topic 8 words Topic 8 weights Topic 9 words Topic 9 weights  \n",
       "0           121.0         polit           319.4    politician            51.5  \n",
       "1            71.0         peopl            54.8          call            37.6  \n",
       "2            66.1           get            38.3           law            28.1  \n",
       "3            40.1            go            30.4             ’            26.3  \n",
       "4            37.7        person            26.4           day            23.1  \n",
       "5            24.3            us            25.1           way            18.3  \n",
       "6            20.4           see            23.2          work            17.9  \n",
       "7            18.0         trump            20.1      democrat            15.8  \n",
       "8            17.3          want            18.2           let            15.2  \n",
       "9            14.2          keep            15.9           job            12.3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)\n",
    "no_top_words = 10\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68c16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
